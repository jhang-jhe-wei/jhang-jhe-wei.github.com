---
title: 2020全國大專校院智慧創新暨跨域整合創作競賽
createdAt: '2020-12-12T22:52:03Z'
categories: Project
tags: [AI,RespberryPi,Python]
description: 本作品為一偵察機器人，此機器人可用於探索室內空間及偵查未完全倒塌的建築物，為了使其適應複雜的地形，我們選用六足機器人當作基底，儘管比起輪軸機器人移動速度較緩慢，但是在克服地形障礙上有更大的優勢。本作品利用強化學習 (Reinforcement Learning) 在電腦上模擬各種地形，使機器人在行走時可以自動依照地形變換動作模式。若將此作品用於救災，可使救災者更加了解倒塌建築物的內部情況，我們在機器人上加裝光學雷達，只要收集足夠的數據就可以產生點雲（point cloud）描繪出整個空間的樣貌，且為了使受困者更加容易被找尋到，本機器人也加裝了攝影機，利用 YOLOv4 達到即時影像辨識將能使搜救更加容易。

---
# 2020全國大專校院智慧創新暨跨域整合創作競賽
## 主題介紹
### 一、題目：泛用環境偵察機 Save Impossible
<iframe width="100%" height="500" src="https://www.youtube.com/embed/jO4WLPvJ7fM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### 二、實用功能描述
<br>
本作品為一偵察機器人，此機器人可用於探索室內空間及偵查未完全倒塌的建築物，為了使其適應複雜的地形，我們選用六足機器人當作基底，儘管比起輪軸機器人移動速度較緩慢，但是在克服地形障礙上有更大的優勢。本作品利用強化學習 (Reinforcement Learning) 在電腦上模擬各種地形，使機器人在行走時可以自動依照地形變換動作模式。若將此作品用於救災，可使救災者更加了解倒塌建築物的內部情況，我們在機器人上加裝光學雷達，只要收集足夠的數據就可以產生點雲（point cloud）描繪出整個空間的樣貌，且為了使受困者更加容易被找尋到，本機器人也加裝了攝影機，利用 YOLOv4 達到即時影像辨識將能使搜救更加容易。

### 三、作品與市場相關產品差異
<br>

|          | 市面上的機器人           | 泛用環境偵察機                                             |
| -------- | ------------------------ | ---------------------------------------------------------- |
| 種類     | 多為輪軸、履帶型機器人   | 六足機器人                                                 |
| 成本     | 約為２萬元               | 8000元                                                     |
| 大小     | 長寬20~40cm、高度20~30cm | 直徑40cm、高度25cm                                         |
| 功能     | 僅移動控制、影像傳輸     | 除移動控制、影像傳輸外，包含地圖建置、地形克服、影像辨識等 |
| 擴充性   | 通常無法擴充             | 在raspberrypi腳位佔滿前可自由新增                          |
| 移動方式 | 系統寫死                 | 使用AI Model使機器人自動適應地形                           |

-----

## 創意構想
### 一、理論基礎
1. **影像傳輸：RTMP**
<br>
RTMP (Real-Time Messaging Protocol) 被稱為即時訊息傳輸協定，是一種建立在TCP上的協定，主要用於傳輸串流音訊及影像資訊，由於只需要單向的傳輸，RTMP與其他傳輸協定如RTSP和SIP相比，擁有較高的穩定性、部屬容易與client端支援度高等優點，因此在本作品中我們選用它作為影像傳輸之協定。<br>
為了確保在動態的網路環境與系統運算資源的變化下，仍有穩定的串流影像，串流影像畫面會被切割成片段 (chunk)，chunk的大小則會動態變化以適應系統環境變化。越大的chunk傳輸效率越佳，但在網路環境變化時反應較不即時，容易出現掉幀、影像拉流 (pull stream) 播放不順；越小的 chunk能夠更即時的反應環境變化，影像拉流 (pull stream) 播放順暢，但計算許多小chunk的分割會提升server端與client端之CPU消耗，過小的封包甚至會導致軟體運行不順。調整預設(動態調整前)的chunk size以符合本作品的硬體環境與低延遲需求。
<img src="還我暑假來影像辨識.png" alt= "影像辨識流程" width= "800">

2. **遙控傳輸：HTTP Methods**
<br>
HTTP (HyperText Transfer Protocol) 是一種常見的網頁傳輸協議，瀏覽網頁的過程就有使用到HTTP。建立在TCP協議上，採用一個請求，一個回復 的機制，客戶端僅需要向伺服端送出 HTTP 請求就可以獲得相應的資源或是伺服器做出預期動作。由於控制機器人動作傳輸的資料量非常的小且不會長時間連續傳送，因此該協議對本作品的機器人控制來說十分的適合。
<img src="還我暑假來http.png" alt= "http流程" width= "800">

3. **地形資料：TCP Socket**
<br>
TCP Socket是對於TCP連線的包裝及應用，一旦TCP連線成功後雙方將可以傳輸訊息一直到連線斷開為止。與HTTP不同，TCP socket的資料收發機制可以自由定義，每一筆封包發送後的回覆為非必要，且連線只須建立一次，因此有利於傳輸大量且低延遲的訊息。主要運用於本作品的Lidar即時環境掃描的資料傳輸。
<img src="還我暑假來tcp-ip-socket.png" alt= "tcp/ip socket流程" width= "800">

4. **機構外型：六足**
<br>
啟發於六足動物的生理結構，使用三足步態 (tripod gait) 為最有效率之動作模式，一次移動三隻腳，而另外三隻腳在地傷。採用多足機構，即使部分腿部在探勘環境時受損，機器人仍可以波型步態 (ripple gait) 或浪行步態 (wave gait) 行走。

<img src="還我暑假來步足法.png" alt= "步足法" width= "400">
<img src="還我暑假來步足法2.png" alt= "步足法" width= "400">

### 二、設計創新說明
在許多的災害事件中，如 2018 年的花蓮地震導致統帥飯店倒塌或是礦災事件，經常會遇到因為空間狹小而導致搜救緩慢的困境，若能在狹小空隙中放入體積不大的偵察機進入探索，那對於搜救將會是一大幫助。然而僅僅是會移動和傳輸影像的機器人是沒有辦法應付各種地形的，若是遇到高低落差過大的地形，很容易發生翻覆，且只能記錄正前方的畫面，沒有辦法了解每個位置周圍的樣子。

而為了解決這些痛點，我們所設計的泛用環境偵察機，利用強化學習、Lidar 及 OpenCV，可以自動適應地形、建構空間地圖及物件分析及追蹤，這是本作品的三大特色，不論是搜救、偵查及探索都能夠實現。

### 三、特殊功能描述
本作品最為特殊的是機器人能自己克服地形障礙，以目前市面上的機器人為例，大部分都是以平面移動為主，當遇到碎石或是凹洞就容易發生卡死的情況，而本作品利用強化學習將可有效的改善這一點，在機器人上安裝的三軸加速度計將作為回授訊號以此作為 AI Model 的 Loss Function，也因此確保機器人在各種地形上皆能夠找到最有效的移動方式。

-----

## 系統架構
### 一、架構說明
1. **簡介**
<br>
本作品的系統架構可分為機器端和 PC 端，機器端包含多足機器人、Camera 及 Lidar 等硬體設備，而 PC 端僅需一台 PC 即可，機器端和 PC 端使用 Wi-Fi 作為傳輸媒介，並且使用多種傳輸協議進行溝通，如 TCP/IP、 HTTP 和 RTMP，用以控制多足機器人、傳輸串流影像和空間數據。
<img src="還我暑假來前後端.png" alt= "前後端" width= "800">

2. **機構**
<br>
本作品為自行設計，由兩片壓克力圓盤搭配六支兩軸機械腳所組成，共有6隻腳12個伺服馬達。為了解決樹莓派 PWM output 腳位不足的情況，在伺服馬達與樹莓派之間加裝了 PWM 驅動器，透過I2C硬體傳輸協定，僅需樹莓派上的 2 個 PIN 即可完成 12 個伺服馬達的控制。
<img src="還我暑假來模型.jpg" alt= "模型" width= "800">
<img src="還我暑假來pwm.jpg" alt= "pwm" width= "800">

3. **影像辨識**
<br>
使用 YOLO 演算法只需要對圖片作一次 CNN 架構便能夠判斷圖形內的物體位置與類別，擁有很快的辨識速度。而 RTMP 串流影像是利用 OpenCV，將串流影像以圖片的格式一幀一幀地抓取，每一幀畫面都可以拿來做圖像辨識，框出各種物件。

4. **地圖建置**
<br>
本系統將使用 Google 開發的 SLAM 演算法 Cartographer，建立出多足機器人行走過的二維地圖，截止至 DEMO，本系統已經完成 Lidar 遠端傳輸，並在 Matplotlib 上顯示目前空間二維圖像。
<img src="還我暑假來lidar.png" alt= "lidat" width= "800">

### 二、軟硬體動作流程
<br>
本系統的功能大致可分為四種，機器人控制、Camera、Lidar、回授訊號，以下說明各功能之動作流程。
<img src="還我暑假來系統架構.png" alt= "系統架構" width= "800">

1. **機器人控制**
<br>
使用者藉由 PC 端 GUI 中輸入多足機器人上的 Raspberry Pi 主機名稱及 Port 完成連線，成功連線後，使用者 PC 端可以按下方向鍵和多組按鍵輸入指令，經由HTTP Request 傳遞移動、收縮和站立等動作指令到多足機器人樹梅派上的 Server，當樹梅派上的 Server 接收到來自使用者的 Request 後，根據不同的指令內容進行動作，使用Adafruit的相關library對 I²C 硬體進行操作，並將資料寫入 PWM 驅動器(PCA9685)，完成對於伺服馬達的控制。

2. **Lidar**
<br>
Lidar 為多足機器人端上的硬體設備，使用 USB 與樹梅派進行連結。透過 Python 上的 rplidar 套件可以直接讀取 Lidar 的感測原始資料，之後經由 TCP Socket 傳輸至 PC 端，並在PC端渲染地圖建模。

3. **Webcam**
<br>
Webcam 為多足機器人端上的硬體設備，使用 USB 與樹梅派進行連結，在樹梅派上建立 Nginx 伺服器，安裝 RTMP 套件後將 Webcam 影像傳輸地端的RTMP Server，再由 PC 端接收串流，以 OpenCV 將串流影像轉換為一幀一幀地呈現至 GUI 上，而由於更新頻率夠快，因此視覺上便是順暢的即時監控影像。

4. **回授訊號**
<br>
三軸加速度計為機器人端的回授訊號之硬體設備，使用 I²C 與樹梅派進行溝通，並使用 TCP Socket 與 PC 端進行通訊，當 PC 端接收到資料後，會將數據放入預先訓練好的模組做運算，改變多足機器人的腳位輸出結果以達到妥當的移動。

### 三、「人機介面設計」（UI）與「使用者體驗」（UX）設計

<img src="還我暑假來操作圖片.png" alt= "GUI" width= "800">

## 結語
這次的競賽要特別感謝我的好隊友們，其中的庭偉(左二)以及琨霖(右二)是從大一課程上認識的夥伴，在該課程的專題上可以感受到他們認真的態度，因此在教授要求我去參加這個比賽時，我第一個想法就是找尋這兩位給力的夥伴組隊，所以真的很感謝他們兩位願意與我組隊參加比賽，讓我們最後獲得了一個不錯的成績，全國第二名。與他們共事我感到十分的開心及滿足。
<br>
<img src="還我暑假來頒獎照片.jpg" alt= "頒獎照片" width= "800">
